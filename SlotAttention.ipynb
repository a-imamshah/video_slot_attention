{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import json\n",
    "import os\n",
    "from typing import Callable\n",
    "from typing import List\n",
    "from typing import Optional\n",
    "from typing import Tuple\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from data import CLEVRDataModule\n",
    "from method import SlotAttentionMethod\n",
    "from model import SlotAttentionModel\n",
    "from params import SlotAttentionParams\n",
    "from utils import ImageLogCallback\n",
    "from utils import rescale\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torchvision import utils as vutils\n",
    "\n",
    "from model import SlotAttentionModel\n",
    "from params import SlotAttentionParams\n",
    "from utils import Tensor\n",
    "from utils import to_rgb_from_tensor\n",
    "\n",
    "class SyntheticDataset(Dataset):\n",
    "    def __init__(self,\n",
    "        data_root: str,\n",
    "        max_num_images: Optional[int],\n",
    "        clevr_transforms: Callable,\n",
    "        split: str = \"train\", #mode\n",
    "        n_steps=10, \n",
    "        dataset_class='spmot', \n",
    "        T=0): #transforms, path\n",
    "\n",
    "        assert dataset_class in ['vmds', 'vor', 'spmot']\n",
    "        self.clevr_transforms = clevr_transforms\n",
    "        #self.split_dict = {\"train\":\"train2017\", \"val\":\"val2017\", \"test\":\"test2017\"}\n",
    "        self.data_root = data_root\n",
    "        self.split = split\n",
    "        \n",
    "\n",
    "        \n",
    "        imgs = np.load(os.path.join(data_root, dataset_class, '{}_{}.npy'.format(dataset_class, split)))\n",
    "        imgs = imgs[:, :n_steps]\n",
    "        imgs = imgs[0:max_num_images,:,:,:,:]\n",
    "        if T and T < n_steps:\n",
    "            imgs = np.concatenate(np.split(imgs, imgs.shape[1]//T, axis=1))\n",
    "        self.imgs = imgs\n",
    "        #self.imgs = [img for img in imgs]\n",
    "        self.num_samples = self.imgs.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.imgs[index]\n",
    "        #print(x.shape)\n",
    "        #print(index)\n",
    "        x = x / 255.0\n",
    "        fr, ch, imx, imy = x.shape\n",
    "        x = x.reshape((fr*ch, imx, imy))\n",
    "        #print(x.shape)\n",
    "        if self.clevr_transforms is not None:\n",
    "            x = self.clevr_transforms(x)\n",
    "        x = x.reshape((fr,ch, imx, imy))\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: limiting the dataset to only images with `num_slots - 1` (9) objects.\n",
      "INFO: restricting the train dataset size to `num_train_images`: 54\n",
      "INFO: restricting the validation dataset size to `num_val_images`: 24\n"
     ]
    }
   ],
   "source": [
    "params = SlotAttentionParams()\n",
    "\n",
    "assert params.num_slots > 1, \"Must have at least 2 slots.\"\n",
    "\n",
    "if params.is_verbose:\n",
    "    print(f\"INFO: limiting the dataset to only images with `num_slots - 1` ({params.num_slots - 1}) objects.\")\n",
    "    if params.num_train_images:\n",
    "        print(f\"INFO: restricting the train dataset size to `num_train_images`: {params.num_train_images}\")\n",
    "    if params.num_val_images:\n",
    "        print(f\"INFO: restricting the validation dataset size to `num_val_images`: {params.num_val_images}\")\n",
    "\n",
    "clevr_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Lambda(rescale),  # rescale between -1 and 1\n",
    "        #transforms.Resize(params.resolution),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = SyntheticDataset(\n",
    "        data_root=params.data_root,\n",
    "        max_num_images=params.num_train_images,\n",
    "        clevr_transforms=clevr_transforms,\n",
    "        split=\"train\",\n",
    "        n_steps = params.n_steps,\n",
    "        dataset_class=params.dataset_class, \n",
    "        T=params.T\n",
    "      )\n",
    "\n",
    "dl= DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=params.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=params.num_workers)\n",
    "\n",
    "\n",
    "# for (idx, batch) in enumerate(dl):\n",
    "#     print(idx)\n",
    "#     print(batch.shape)\n",
    "\n",
    "# print(len(dl))\n",
    "\n",
    "perm = torch.randperm(params.batch_size)\n",
    "idx = perm[: params.n_samples]\n",
    "batch = next(iter(dl))[idx]\n",
    "if params.gpus > 0:\n",
    "    batch = batch.cuda()\n",
    "\n",
    "out = to_rgb_from_tensor(\n",
    "        torch.cat(\n",
    "            [\n",
    "                batch.unsqueeze(1),  # original images\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "batch_size, num_slots, frames, C, H, W = out.shape\n",
    "print(out.shape)\n",
    "out = out[:,:,-1,:,:,:]\n",
    "\n",
    "images = vutils.make_grid(out.reshape(batch_size * out.shape[1], C, H, W).cpu(), normalize=False, nrow=out.shape[1],)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slot",
   "language": "python",
   "name": "slot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
